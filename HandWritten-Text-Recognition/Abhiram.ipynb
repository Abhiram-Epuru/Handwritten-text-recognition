{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e19eca6-12f0-4002-be29-310b663c3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cc1ab7-4f35-4fb4-8646-5427023328f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(\"data.csv\")\n",
    "test_df=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b137961f-493e-4106-92f6-fc8defd77b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ac3d3d-2c31-42a2-a2cd-bbde97e83d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d22159-6aa9-4243-9eb1-9930805d9f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6abdc4f-0de5-44fe-8890-0e373fa58fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data_df['label']\n",
    "x=data_df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cbd769-0945-4fd0-9474-1f0f06309df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_for_test_data=test_df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2dc0e70-415a-4550-b749-580b328f87cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af9ef23-c970-49d3-84bf-cdbc15d6ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "some_digit=1267\n",
    "some_digit_image = x.iloc[some_digit].to_numpy()\n",
    "plt.imshow(np.reshape(some_digit_image, (28,28)))\n",
    "print(y[some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7326937f-3c76-4539-8baf-8ad3c52a3760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot( x='label', data=data_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9428a66-a1d8-47e1-aa02-0d69475a163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.70, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d3ff0b-8af1-4b40-bbff-0a4dab447ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12600, 784), (12600,), (29400, 784), (29400,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d1bc77-bbc5-44e3-a39f-668855d9ed44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12600, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train,y_train)\n",
    "x_train=scaler.transform(x_train)\n",
    "x_test= scaler.transform(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6fcec14-9bac-4618-8010-9fb53b05a99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, ..., 2, 4, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "ratio='70:30'\n",
    "K=5\n",
    "classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred=classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43b70162-c94e-469e-8196-9e0bbdb2ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6fe360-ff63-4c03-a5f2-6bbe978ad16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratio: 70:30, K: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nRatio: {ratio}, K: {K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23e02f04-0f6d-4513-a5da-21be0b7d83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9191836734693878\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb077e56-c534-4785-809f-f20eaf43937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      2860\n",
      "           1       0.91      0.99      0.95      3258\n",
      "           2       0.95      0.90      0.92      2947\n",
      "           3       0.89      0.93      0.91      3104\n",
      "           4       0.92      0.90      0.91      2835\n",
      "           5       0.90      0.89      0.90      2659\n",
      "           6       0.95      0.96      0.96      2898\n",
      "           7       0.92      0.90      0.91      3087\n",
      "           8       0.95      0.85      0.90      2823\n",
      "           9       0.87      0.88      0.88      2929\n",
      "\n",
      "    accuracy                           0.92     29400\n",
      "   macro avg       0.92      0.92      0.92     29400\n",
      "weighted avg       0.92      0.92      0.92     29400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bcba021-18d5-442d-bbf4-b53fc4692b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2806    3    6    5    3   10   19    2    5    1]\n",
      " [   3 3225    6    4    3    2    8    3    2    2]\n",
      " [  39   66 2657   71   21    0   30   32   25    6]\n",
      " [  14   21   34 2880    3   51    4   36   44   17]\n",
      " [   5   64   24    9 2561   17   11   13    1  130]\n",
      " [  21   28    7  116   19 2369   50    9   17   23]\n",
      " [  53   12   10    7   12   18 2781    0    5    0]\n",
      " [   6   61   14   19   34    0    0 2767    3  183]\n",
      " [  33   49   36   76   35  145   10   12 2386   41]\n",
      " [  22   14   13   38   92   10    0  136   12 2592]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa866c60-d16b-46a6-9ca1-702a95cc232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratio: 0.6, K: 2\n",
      "Accuracy: 0.9073015873015873\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2443\n",
      "           1       0.91      0.99      0.95      2800\n",
      "           2       0.89      0.92      0.91      2509\n",
      "           3       0.86      0.92      0.89      2693\n",
      "           4       0.87      0.93      0.90      2401\n",
      "           5       0.88      0.88      0.88      2288\n",
      "           6       0.97      0.93      0.95      2465\n",
      "           7       0.90      0.92      0.91      2660\n",
      "           8       0.96      0.78      0.87      2432\n",
      "           9       0.94      0.80      0.86      2509\n",
      "\n",
      "    accuracy                           0.91     25200\n",
      "   macro avg       0.91      0.91      0.91     25200\n",
      "weighted avg       0.91      0.91      0.91     25200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2408    2    7    4    2    7   10    1    2    0]\n",
      " [   2 2782    8    0    1    1    1    2    2    1]\n",
      " [  50   62 2312   32   14    2   16   11    8    2]\n",
      " [  14   19   87 2480    3   33    1   20   26   10]\n",
      " [   5   50   34    6 2240    8    5   11    1   41]\n",
      " [  21   14    9  171   19 2004   27   11    9    3]\n",
      " [  78    9   32    7   10   46 2282    0    1    0]\n",
      " [   6   53   31   20   53    0    1 2434    3   59]\n",
      " [  31   50   51  127   50  172   12   13 1908   18]\n",
      " [  21   16   14   32  173   13    0  208   18 2014]]\n",
      "\n",
      "Ratio: 0.6, K: 4\n",
      "Accuracy: 0.9215079365079365\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      2443\n",
      "           1       0.92      0.99      0.95      2800\n",
      "           2       0.94      0.92      0.93      2509\n",
      "           3       0.89      0.93      0.91      2693\n",
      "           4       0.91      0.92      0.92      2401\n",
      "           5       0.90      0.89      0.90      2288\n",
      "           6       0.96      0.95      0.96      2465\n",
      "           7       0.92      0.92      0.92      2660\n",
      "           8       0.96      0.84      0.90      2432\n",
      "           9       0.90      0.86      0.88      2509\n",
      "\n",
      "    accuracy                           0.92     25200\n",
      "   macro avg       0.92      0.92      0.92     25200\n",
      "weighted avg       0.92      0.92      0.92     25200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2398    1    7    5    1    8   17    1    4    1]\n",
      " [   2 2783    5    1    0    1    2    2    2    2]\n",
      " [  41   47 2304   38   18    0   21   20   13    7]\n",
      " [  14   20   47 2498    3   35    2   22   34   18]\n",
      " [   3   52   21    5 2216   14    7   10    4   69]\n",
      " [  13   18    7  120   14 2039   37    8   16   16]\n",
      " [  45    7   23    4   11   28 2346    0    1    0]\n",
      " [   3   45   13   14   35    0    0 2442    4  104]\n",
      " [  27   50   24   77   33  129    7   11 2042   32]\n",
      " [  22   10   13   31  109   12    0  148   10 2154]]\n",
      "\n",
      "Ratio: 0.6, K: 5\n",
      "Accuracy: 0.9244444444444444\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2443\n",
      "           1       0.92      0.99      0.96      2800\n",
      "           2       0.95      0.91      0.93      2509\n",
      "           3       0.90      0.92      0.91      2693\n",
      "           4       0.92      0.91      0.91      2401\n",
      "           5       0.90      0.90      0.90      2288\n",
      "           6       0.96      0.97      0.96      2465\n",
      "           7       0.93      0.91      0.92      2660\n",
      "           8       0.95      0.85      0.90      2432\n",
      "           9       0.88      0.89      0.88      2509\n",
      "\n",
      "    accuracy                           0.92     25200\n",
      "   macro avg       0.92      0.92      0.92     25200\n",
      "weighted avg       0.92      0.92      0.92     25200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2394    1    4    6    2    8   22    2    4    0]\n",
      " [   1 2781    4    2    1    1    6    1    1    2]\n",
      " [  30   44 2295   48   19    0   23   26   18    6]\n",
      " [  11   21   36 2488    4   51    3   23   39   17]\n",
      " [   4   47   20    6 2181   15    9   10    4  105]\n",
      " [  15   20    6   93   15 2062   39    8   13   17]\n",
      " [  36    6    6    5    7   24 2379    0    2    0]\n",
      " [   4   41   13   12   34    0    0 2414    5  137]\n",
      " [  22   43   27   68   32  113    9   11 2077   30]\n",
      " [  20   12   11   27   81   11    0  108   14 2225]]\n",
      "\n",
      "Ratio: 0.6, K: 6\n",
      "Accuracy: 0.9230952380952381\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2443\n",
      "           1       0.91      0.99      0.95      2800\n",
      "           2       0.94      0.92      0.93      2509\n",
      "           3       0.90      0.93      0.91      2693\n",
      "           4       0.91      0.92      0.92      2401\n",
      "           5       0.90      0.90      0.90      2288\n",
      "           6       0.96      0.96      0.96      2465\n",
      "           7       0.92      0.91      0.91      2660\n",
      "           8       0.96      0.84      0.90      2432\n",
      "           9       0.89      0.87      0.88      2509\n",
      "\n",
      "    accuracy                           0.92     25200\n",
      "   macro avg       0.92      0.92      0.92     25200\n",
      "weighted avg       0.92      0.92      0.92     25200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2395    0    4    6    1    9   19    3    6    0]\n",
      " [   0 2782    4    2    0    2    6    1    1    2]\n",
      " [  34   54 2297   43   17    0   21   23   13    7]\n",
      " [  12   20   38 2496    4   41    3   25   37   17]\n",
      " [   4   52   23    5 2208   16    6    8    2   77]\n",
      " [  13   21    7  105   15 2061   38   10    8   10]\n",
      " [  43    5    7    5    7   26 2369    0    3    0]\n",
      " [   2   47   16   12   45    1    1 2418    4  114]\n",
      " [  24   49   23   75   30  128   10   11 2052   30]\n",
      " [  19   14   13   27   94    8    0  138   12 2184]]\n",
      "\n",
      "Ratio: 0.6, K: 7\n",
      "Accuracy: 0.9235714285714286\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2443\n",
      "           1       0.91      0.99      0.95      2800\n",
      "           2       0.95      0.91      0.93      2509\n",
      "           3       0.91      0.92      0.92      2693\n",
      "           4       0.92      0.91      0.92      2401\n",
      "           5       0.90      0.90      0.90      2288\n",
      "           6       0.95      0.96      0.96      2465\n",
      "           7       0.92      0.90      0.91      2660\n",
      "           8       0.96      0.85      0.90      2432\n",
      "           9       0.88      0.88      0.88      2509\n",
      "\n",
      "    accuracy                           0.92     25200\n",
      "   macro avg       0.92      0.92      0.92     25200\n",
      "weighted avg       0.92      0.92      0.92     25200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2393    1    4    6    1   10   20    3    5    0]\n",
      " [   0 2782    4    1    1    2    6    1    1    2]\n",
      " [  27   55 2285   48   19    0   27   25   17    6]\n",
      " [  13   21   32 2486    3   53    4   26   38   17]\n",
      " [   3   52   22    5 2194   15    7   10    1   92]\n",
      " [  13   21    8   86   17 2062   40    8   16   17]\n",
      " [  38    5    7    4    9   21 2378    0    3    0]\n",
      " [   2   48   15   10   39    1    1 2397    3  144]\n",
      " [  23   44   24   62   28  124    8    8 2077   34]\n",
      " [  21   16   13   27   78    7    0  116   11 2220]]\n",
      "\n",
      "Ratio: 0.6, K: 10\n",
      "Accuracy: 0.9195634920634921\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2443\n",
      "           1       0.90      0.99      0.95      2800\n",
      "           2       0.95      0.90      0.92      2509\n",
      "           3       0.90      0.92      0.91      2693\n",
      "           4       0.92      0.92      0.92      2401\n",
      "           5       0.90      0.89      0.90      2288\n",
      "           6       0.95      0.96      0.96      2465\n",
      "           7       0.92      0.90      0.91      2660\n",
      "           8       0.96      0.85      0.90      2432\n",
      "           9       0.87      0.88      0.87      2509\n",
      "\n",
      "    accuracy                           0.92     25200\n",
      "   macro avg       0.92      0.92      0.92     25200\n",
      "weighted avg       0.92      0.92      0.92     25200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2388    2    5    5    2   10   23    3    5    0]\n",
      " [   0 2785    3    1    1    1    5    1    1    2]\n",
      " [  32   66 2260   50   19    1   30   26   18    7]\n",
      " [  11   25   35 2485    4   48    4   31   30   20]\n",
      " [   2   53   21    6 2198   14    7    9    2   89]\n",
      " [  18   24    5   98   15 2044   43    8   13   20]\n",
      " [  43    7    8    6    7   21 2367    0    6    0]\n",
      " [   3   60   12   10   34    0    0 2390    2  149]\n",
      " [  27   56   18   68   23  123   10   10 2060   37]\n",
      " [  18   16   12   32   87    6    0  128   14 2196]]\n",
      "\n",
      "Ratio: 0.7, K: 2\n",
      "Accuracy: 0.9020408163265307\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      2860\n",
      "           1       0.90      0.99      0.94      3258\n",
      "           2       0.89      0.90      0.90      2947\n",
      "           3       0.85      0.92      0.89      3104\n",
      "           4       0.88      0.93      0.90      2835\n",
      "           5       0.87      0.86      0.87      2659\n",
      "           6       0.97      0.92      0.94      2898\n",
      "           7       0.89      0.91      0.90      3087\n",
      "           8       0.96      0.78      0.86      2823\n",
      "           9       0.93      0.81      0.86      2929\n",
      "\n",
      "    accuracy                           0.90     29400\n",
      "   macro avg       0.90      0.90      0.90     29400\n",
      "weighted avg       0.90      0.90      0.90     29400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2811    5    9    6    3    7   15    0    4    0]\n",
      " [   2 3235   12    0    2    0    0    2    3    2]\n",
      " [  59  100 2667   49   19    0   23   12   13    5]\n",
      " [  17   23   93 2870    3   35    1   26   25   11]\n",
      " [   9   64   34    6 2629   11    5   18    2   57]\n",
      " [  34   25   13  217   25 2282   29   11   16    7]\n",
      " [  96   14   44    9   18   57 2660    0    0    0]\n",
      " [   6   61   34   31   59    2    1 2817    4   72]\n",
      " [  44   58   66  146   56  204   16   18 2191   24]\n",
      " [  26   15   16   39  185   16    0  258   16 2358]]\n",
      "\n",
      "Ratio: 0.7, K: 4\n",
      "Accuracy: 0.9155442176870748\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      2860\n",
      "           1       0.91      0.99      0.95      3258\n",
      "           2       0.93      0.90      0.92      2947\n",
      "           3       0.88      0.93      0.90      3104\n",
      "           4       0.91      0.91      0.91      2835\n",
      "           5       0.90      0.88      0.89      2659\n",
      "           6       0.96      0.95      0.95      2898\n",
      "           7       0.91      0.91      0.91      3087\n",
      "           8       0.96      0.83      0.89      2823\n",
      "           9       0.89      0.86      0.87      2929\n",
      "\n",
      "    accuracy                           0.92     29400\n",
      "   macro avg       0.92      0.91      0.91     29400\n",
      "weighted avg       0.92      0.92      0.92     29400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2810    3    6    6    2   11   15    2    5    0]\n",
      " [   2 3231    7    3    2    2    4    3    2    2]\n",
      " [  52   68 2664   64   19    0   26   25   21    8]\n",
      " [  14   20   52 2878    3   44    3   30   41   19]\n",
      " [   4   67   32    8 2589   16   10   14    3   92]\n",
      " [  22   24   14  151   19 2332   48    8   20   21]\n",
      " [  61   13   26    7   16   20 2751    0    4    0]\n",
      " [   4   61   18   17   40    0    0 2817    3  127]\n",
      " [  34   56   41   91   35  164   13   14 2339   36]\n",
      " [  26   12   13   45  122    8    0  187   10 2506]]\n",
      "\n",
      "Ratio: 0.7, K: 5\n",
      "Accuracy: 0.9191836734693878\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      2860\n",
      "           1       0.91      0.99      0.95      3258\n",
      "           2       0.95      0.90      0.92      2947\n",
      "           3       0.89      0.93      0.91      3104\n",
      "           4       0.92      0.90      0.91      2835\n",
      "           5       0.90      0.89      0.90      2659\n",
      "           6       0.95      0.96      0.96      2898\n",
      "           7       0.92      0.90      0.91      3087\n",
      "           8       0.95      0.85      0.90      2823\n",
      "           9       0.87      0.88      0.88      2929\n",
      "\n",
      "    accuracy                           0.92     29400\n",
      "   macro avg       0.92      0.92      0.92     29400\n",
      "weighted avg       0.92      0.92      0.92     29400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2806    3    6    5    3   10   19    2    5    1]\n",
      " [   3 3225    6    4    3    2    8    3    2    2]\n",
      " [  39   66 2657   71   21    0   30   32   25    6]\n",
      " [  14   21   34 2880    3   51    4   36   44   17]\n",
      " [   5   64   24    9 2561   17   11   13    1  130]\n",
      " [  21   28    7  116   19 2369   50    9   17   23]\n",
      " [  53   12   10    7   12   18 2781    0    5    0]\n",
      " [   6   61   14   19   34    0    0 2767    3  183]\n",
      " [  33   49   36   76   35  145   10   12 2386   41]\n",
      " [  22   14   13   38   92   10    0  136   12 2592]]\n",
      "\n",
      "Ratio: 0.7, K: 6\n",
      "Accuracy: 0.9175510204081633\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      2860\n",
      "           1       0.90      0.99      0.95      3258\n",
      "           2       0.94      0.90      0.92      2947\n",
      "           3       0.89      0.93      0.91      3104\n",
      "           4       0.92      0.91      0.91      2835\n",
      "           5       0.90      0.88      0.89      2659\n",
      "           6       0.96      0.95      0.95      2898\n",
      "           7       0.91      0.90      0.91      3087\n",
      "           8       0.96      0.84      0.89      2823\n",
      "           9       0.88      0.87      0.87      2929\n",
      "\n",
      "    accuracy                           0.92     29400\n",
      "   macro avg       0.92      0.92      0.92     29400\n",
      "weighted avg       0.92      0.92      0.92     29400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2809    2    3    5    5    9   18    3    5    1]\n",
      " [   1 3231    5    4    2    2    7    2    2    2]\n",
      " [  43   66 2661   69   19    0   26   28   26    9]\n",
      " [  13   26   36 2886    2   42    4   35   41   19]\n",
      " [   4   66   25    8 2589   15    9   13    1  105]\n",
      " [  27   28    7  132   21 2351   52   10   10   21]\n",
      " [  63   13   15    6   12   23 2761    0    5    0]\n",
      " [   5   68   17   22   37    0    0 2780    2  156]\n",
      " [  35   56   36   80   33  157   12   14 2358   42]\n",
      " [  20   18   15   41  105    6    0  161   13 2550]]\n",
      "\n",
      "Ratio: 0.7, K: 7\n",
      "Accuracy: 0.9178231292517007\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2860\n",
      "           1       0.90      0.99      0.94      3258\n",
      "           2       0.95      0.89      0.92      2947\n",
      "           3       0.90      0.92      0.91      3104\n",
      "           4       0.92      0.90      0.91      2835\n",
      "           5       0.90      0.89      0.89      2659\n",
      "           6       0.95      0.96      0.95      2898\n",
      "           7       0.92      0.89      0.91      3087\n",
      "           8       0.95      0.85      0.90      2823\n",
      "           9       0.86      0.89      0.87      2929\n",
      "\n",
      "    accuracy                           0.92     29400\n",
      "   macro avg       0.92      0.92      0.92     29400\n",
      "weighted avg       0.92      0.92      0.92     29400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2800    3    3    6    6    9   23    2    7    1]\n",
      " [   0 3232    7    3    2    2    6    2    2    2]\n",
      " [  38   72 2633   80   22    0   34   29   30    9]\n",
      " [  15   27   32 2871    1   55    4   38   39   22]\n",
      " [   5   64   24    9 2557   19   10   14    1  132]\n",
      " [  27   31    6  112   18 2358   55   11   18   23]\n",
      " [  54   13   12    5   10   18 2779    1    6    0]\n",
      " [   5   67   16   14   38    0    0 2755    2  190]\n",
      " [  26   55   26   66   36  151   13   11 2396   43]\n",
      " [  23   19   14   38   87    7    0  127   11 2603]]\n",
      "\n",
      "Ratio: 0.7, K: 10\n",
      "Accuracy: 0.911734693877551\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      2860\n",
      "           1       0.89      0.99      0.94      3258\n",
      "           2       0.95      0.88      0.91      2947\n",
      "           3       0.89      0.92      0.91      3104\n",
      "           4       0.92      0.91      0.91      2835\n",
      "           5       0.90      0.88      0.89      2659\n",
      "           6       0.95      0.95      0.95      2898\n",
      "           7       0.91      0.89      0.90      3087\n",
      "           8       0.95      0.83      0.89      2823\n",
      "           9       0.86      0.87      0.87      2929\n",
      "\n",
      "    accuracy                           0.91     29400\n",
      "   macro avg       0.91      0.91      0.91     29400\n",
      "weighted avg       0.91      0.91      0.91     29400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2796    3    6    5    6   12   22    2    7    1]\n",
      " [   0 3234    4    4    2    1    7    0    3    3]\n",
      " [  42   84 2595   77   22    1   39   43   34   10]\n",
      " [  19   32   35 2861    3   48    4   39   42   21]\n",
      " [   4   67   24    9 2566   17    7   14    4  123]\n",
      " [  27   36    5  123   20 2333   58   12   19   26]\n",
      " [  61   14   12    7    9   26 2762    1    6    0]\n",
      " [   6   81   13   13   41    1    0 2742    2  188]\n",
      " [  33   73   24   76   32  153   12   15 2357   48]\n",
      " [  20   21   14   40   97    7    0  157   14 2559]]\n",
      "\n",
      "Ratio: 0.75, K: 2\n",
      "Accuracy: 0.8980952380952381\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3057\n",
      "           1       0.90      0.99      0.94      3521\n",
      "           2       0.88      0.90      0.89      3153\n",
      "           3       0.85      0.92      0.88      3308\n",
      "           4       0.87      0.92      0.90      3057\n",
      "           5       0.87      0.86      0.86      2849\n",
      "           6       0.96      0.92      0.94      3098\n",
      "           7       0.88      0.91      0.89      3313\n",
      "           8       0.97      0.77      0.86      3011\n",
      "           9       0.93      0.79      0.85      3133\n",
      "\n",
      "    accuracy                           0.90     31500\n",
      "   macro avg       0.90      0.90      0.90     31500\n",
      "weighted avg       0.90      0.90      0.90     31500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3007    3   11    6    3    5   17    2    3    0]\n",
      " [   5 3490   15    1    2    0    1    2    3    2]\n",
      " [  77   95 2850   56   21    2   22   13   12    5]\n",
      " [  17   25  122 3032    5   39    3   30   25   10]\n",
      " [  12   70   32   10 2811   16    7   23    3   73]\n",
      " [  45   25   17  225   27 2436   36   13   15   10]\n",
      " [  97   15   59    7   18   49 2853    0    0    0]\n",
      " [   7   67   37   36   76    4    1 3003    3   79]\n",
      " [  52   70   59  162   54  228   18   20 2326   22]\n",
      " [  29   16   21   42  198   18    0  310   17 2482]]\n",
      "\n",
      "Ratio: 0.75, K: 4\n",
      "Accuracy: 0.9134285714285715\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3057\n",
      "           1       0.90      0.99      0.95      3521\n",
      "           2       0.92      0.90      0.91      3153\n",
      "           3       0.88      0.92      0.90      3308\n",
      "           4       0.92      0.91      0.91      3057\n",
      "           5       0.90      0.88      0.89      2849\n",
      "           6       0.96      0.95      0.95      3098\n",
      "           7       0.90      0.91      0.91      3313\n",
      "           8       0.95      0.83      0.89      3011\n",
      "           9       0.88      0.86      0.87      3133\n",
      "\n",
      "    accuracy                           0.91     31500\n",
      "   macro avg       0.91      0.91      0.91     31500\n",
      "weighted avg       0.91      0.91      0.91     31500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3004    3    8    8    2   11   15    2    4    0]\n",
      " [   3 3489   10    4    2    2    4    3    2    2]\n",
      " [  55   77 2827   84   17    1   25   30   26   11]\n",
      " [  16   24   56 3055    4   49    5   38   39   22]\n",
      " [   8   72   32    9 2779   18   12   16    5  106]\n",
      " [  30   27   13  155   18 2500   46   12   22   26]\n",
      " [  66   15   36    6   12   23 2937    0    3    0]\n",
      " [   5   69   22   17   42    0    0 3008    3  147]\n",
      " [  40   70   41   98   32  178   12   12 2491   37]\n",
      " [  24   17   19   42  124    6    0  204   14 2683]]\n",
      "\n",
      "Ratio: 0.75, K: 5\n",
      "Accuracy: 0.9166031746031746\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3057\n",
      "           1       0.91      0.99      0.95      3521\n",
      "           2       0.94      0.90      0.92      3153\n",
      "           3       0.89      0.92      0.91      3308\n",
      "           4       0.93      0.90      0.91      3057\n",
      "           5       0.90      0.89      0.89      2849\n",
      "           6       0.95      0.96      0.96      3098\n",
      "           7       0.92      0.89      0.90      3313\n",
      "           8       0.95      0.84      0.89      3011\n",
      "           9       0.86      0.88      0.87      3133\n",
      "\n",
      "    accuracy                           0.92     31500\n",
      "   macro avg       0.92      0.92      0.92     31500\n",
      "weighted avg       0.92      0.92      0.92     31500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2996    4    5   11    5   11   18    2    3    2]\n",
      " [   1 3484    9    5    3    2   10    3    2    2]\n",
      " [  43   73 2833   83   15    1   32   32   30   11]\n",
      " [  14   28   41 3051    4   59    5   43   43   20]\n",
      " [   6   66   24   10 2753   18   13   16    2  149]\n",
      " [  29   28   10  120   17 2533   52   12   19   29]\n",
      " [  55   15   16    7    9   22 2970    0    4    0]\n",
      " [   7   67   21   16   41    0    0 2955    3  203]\n",
      " [  31   59   33   84   36  174   12   15 2526   41]\n",
      " [  21   17   20   39   90    9    0  150   15 2772]]\n",
      "\n",
      "Ratio: 0.75, K: 6\n",
      "Accuracy: 0.9138412698412698\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      3057\n",
      "           1       0.90      0.99      0.94      3521\n",
      "           2       0.94      0.89      0.91      3153\n",
      "           3       0.88      0.92      0.90      3308\n",
      "           4       0.92      0.91      0.91      3057\n",
      "           5       0.89      0.88      0.89      2849\n",
      "           6       0.95      0.95      0.95      3098\n",
      "           7       0.91      0.90      0.90      3313\n",
      "           8       0.96      0.83      0.89      3011\n",
      "           9       0.88      0.87      0.87      3133\n",
      "\n",
      "    accuracy                           0.91     31500\n",
      "   macro avg       0.92      0.91      0.91     31500\n",
      "weighted avg       0.91      0.91      0.91     31500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2992    3    6    8    8   10   22    2    5    1]\n",
      " [   0 3491    9    3    2    2    8    2    2    2]\n",
      " [  52   79 2821   81   19    2   31   31   27   10]\n",
      " [  14   32   49 3052    4   49    5   40   39   24]\n",
      " [   5   74   27   10 2775   19   12   15    3  117]\n",
      " [  30   29   10  143   16 2512   60   14   12   23]\n",
      " [  70   15   22    6   11   26 2944    0    4    0]\n",
      " [   6   79   20   19   40    0    0 2980    1  168]\n",
      " [  31   68   33   90   36  186   11   14 2501   41]\n",
      " [  23   21   19   42  108    7    0  179   16 2718]]\n",
      "\n",
      "Ratio: 0.75, K: 7\n",
      "Accuracy: 0.9137142857142857\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      3057\n",
      "           1       0.90      0.99      0.94      3521\n",
      "           2       0.94      0.89      0.91      3153\n",
      "           3       0.89      0.92      0.90      3308\n",
      "           4       0.92      0.90      0.91      3057\n",
      "           5       0.90      0.88      0.89      2849\n",
      "           6       0.95      0.96      0.95      3098\n",
      "           7       0.92      0.89      0.90      3313\n",
      "           8       0.95      0.84      0.89      3011\n",
      "           9       0.85      0.89      0.87      3133\n",
      "\n",
      "    accuracy                           0.91     31500\n",
      "   macro avg       0.92      0.91      0.91     31500\n",
      "weighted avg       0.91      0.91      0.91     31500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2991    3    5    8    8   11   22    2    6    1]\n",
      " [   0 3489   11    2    4    1    8    2    2    2]\n",
      " [  48   81 2793   95   21    1   38   37   31    8]\n",
      " [  15   31   52 3033    4   57    5   41   46   24]\n",
      " [   7   71   25    9 2740   18    9   16    4  158]\n",
      " [  33   31    9  124   16 2517   61   12   21   25]\n",
      " [  63   16   15    6    8   24 2960    1    5    0]\n",
      " [   6   78   17   13   40    0    0 2951    1  207]\n",
      " [  32   67   25   77   38  169   13   11 2528   51]\n",
      " [  23   21   16   41   87    7    0  143   15 2780]]\n",
      "\n",
      "Ratio: 0.75, K: 10\n",
      "Accuracy: 0.9100317460317461\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      3057\n",
      "           1       0.88      0.99      0.93      3521\n",
      "           2       0.95      0.87      0.91      3153\n",
      "           3       0.89      0.92      0.90      3308\n",
      "           4       0.92      0.90      0.91      3057\n",
      "           5       0.89      0.88      0.89      2849\n",
      "           6       0.95      0.95      0.95      3098\n",
      "           7       0.91      0.89      0.90      3313\n",
      "           8       0.95      0.83      0.89      3011\n",
      "           9       0.86      0.87      0.87      3133\n",
      "\n",
      "    accuracy                           0.91     31500\n",
      "   macro avg       0.91      0.91      0.91     31500\n",
      "weighted avg       0.91      0.91      0.91     31500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2994    3    7    6    7   12   22    1    4    1]\n",
      " [   0 3493    9    3    2    0    7    1    4    2]\n",
      " [  51  101 2746   97   20    5   38   47   37   11]\n",
      " [  14   43   45 3029    4   54    6   42   46   25]\n",
      " [   9   76   25    9 2752   17    8   14    2  145]\n",
      " [  32   40    8  124   17 2501   65   13   20   29]\n",
      " [  71   16   12    6    7   27 2952    1    6    0]\n",
      " [   7   90   12   10   40    0    0 2965    2  187]\n",
      " [  35   83   22   86   29  180   11   13 2499   53]\n",
      " [  21   25   16   41  103    6    0  173   13 2735]]\n",
      "\n",
      "Ratio: 0.8, K: 2\n",
      "Accuracy: 0.8916369047619047\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      3275\n",
      "           1       0.89      0.99      0.94      3761\n",
      "           2       0.87      0.90      0.88      3357\n",
      "           3       0.84      0.91      0.87      3509\n",
      "           4       0.87      0.91      0.89      3265\n",
      "           5       0.86      0.85      0.85      3034\n",
      "           6       0.96      0.91      0.94      3325\n",
      "           7       0.87      0.90      0.89      3526\n",
      "           8       0.97      0.76      0.85      3214\n",
      "           9       0.92      0.79      0.85      3334\n",
      "\n",
      "    accuracy                           0.89     33600\n",
      "   macro avg       0.89      0.89      0.89     33600\n",
      "weighted avg       0.89      0.89      0.89     33600\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3218    3   13    6    4    9   17    2    3    0]\n",
      " [   6 3726   15    0    3    1    3    4    1    2]\n",
      " [  85  110 3019   62   18    3   21   21   13    5]\n",
      " [  26   30  155 3180    4   39    4   31   27   13]\n",
      " [  16   86   50   12 2972   17    5   26    4   77]\n",
      " [  51   26   28  261   28 2565   38   13   13   11]\n",
      " [ 126   16   66    6   27   59 3025    0    0    0]\n",
      " [   8   80   41   42   75    3    1 3178    5   93]\n",
      " [  53   79   72  180   58  253   24   24 2448   23]\n",
      " [  29   15   23   51  211   19    0  336   22 2628]]\n",
      "\n",
      "Ratio: 0.8, K: 4\n",
      "Accuracy: 0.9080952380952381\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      3275\n",
      "           1       0.90      0.99      0.94      3761\n",
      "           2       0.92      0.90      0.91      3357\n",
      "           3       0.87      0.92      0.89      3509\n",
      "           4       0.91      0.91      0.91      3265\n",
      "           5       0.89      0.87      0.88      3034\n",
      "           6       0.96      0.94      0.95      3325\n",
      "           7       0.90      0.90      0.90      3526\n",
      "           8       0.95      0.81      0.88      3214\n",
      "           9       0.88      0.86      0.87      3334\n",
      "\n",
      "    accuracy                           0.91     33600\n",
      "   macro avg       0.91      0.91      0.91     33600\n",
      "weighted avg       0.91      0.91      0.91     33600\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3205    3   10    8    3   16   20    2    8    0]\n",
      " [   2 3724   11    4    1    2    8    6    2    1]\n",
      " [  62   80 3006   91   17    2   27   33   28   11]\n",
      " [  24   30   65 3220    5   56    5   41   40   23]\n",
      " [   7   83   42   10 2956   17   11   21    5  113]\n",
      " [  36   28   17  180   20 2638   50   11   24   30]\n",
      " [  88   14   37    6   15   30 3127    1    7    0]\n",
      " [   6   84   27   27   41    0    0 3165    3  173]\n",
      " [  48   78   46  110   38  203   18   12 2617   44]\n",
      " [  28   19   17   49  140    3    0  211   13 2854]]\n",
      "\n",
      "Ratio: 0.8, K: 5\n",
      "Accuracy: 0.9096428571428572\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      3275\n",
      "           1       0.90      0.99      0.94      3761\n",
      "           2       0.93      0.88      0.91      3357\n",
      "           3       0.87      0.92      0.89      3509\n",
      "           4       0.92      0.89      0.91      3265\n",
      "           5       0.89      0.88      0.88      3034\n",
      "           6       0.95      0.95      0.95      3325\n",
      "           7       0.91      0.88      0.90      3526\n",
      "           8       0.95      0.83      0.88      3214\n",
      "           9       0.85      0.88      0.87      3334\n",
      "\n",
      "    accuracy                           0.91     33600\n",
      "   macro avg       0.91      0.91      0.91     33600\n",
      "weighted avg       0.91      0.91      0.91     33600\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3207    4    8    9    6   15   19    2    5    0]\n",
      " [   0 3723    9    5    3    2   11    6    1    1]\n",
      " [  52   80 2962  114   18    4   38   47   35    7]\n",
      " [  19   31   51 3218    5   60    6   44   50   25]\n",
      " [   6   79   34   13 2922   18   10   18    2  163]\n",
      " [  33   30   13  160   16 2663   59   12   17   31]\n",
      " [  81   17   20    6   10   28 3156    1    6    0]\n",
      " [   4   83   25   25   40    0    1 3116    2  230]\n",
      " [  39   69   37   96   40  198   17   16 2653   49]\n",
      " [  25   17   19   48  101    7    0  158   15 2944]]\n",
      "\n",
      "Ratio: 0.8, K: 6\n",
      "Accuracy: 0.9073809523809524\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3275\n",
      "           1       0.89      0.99      0.94      3761\n",
      "           2       0.93      0.88      0.90      3357\n",
      "           3       0.87      0.92      0.89      3509\n",
      "           4       0.92      0.90      0.91      3265\n",
      "           5       0.89      0.87      0.88      3034\n",
      "           6       0.95      0.95      0.95      3325\n",
      "           7       0.91      0.89      0.90      3526\n",
      "           8       0.95      0.82      0.88      3214\n",
      "           9       0.87      0.87      0.87      3334\n",
      "\n",
      "    accuracy                           0.91     33600\n",
      "   macro avg       0.91      0.91      0.91     33600\n",
      "weighted avg       0.91      0.91      0.91     33600\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3203    3    9   11    6   16   20    1    6    0]\n",
      " [   0 3730    7    5    3    2    8    3    1    2]\n",
      " [  63   86 2956  109   19    5   36   43   32    8]\n",
      " [  18   35   59 3229    5   47    6   46   41   23]\n",
      " [   6   87   37   11 2938   18   13   18    3  134]\n",
      " [  39   38   14  169   19 2635   60   10   22   28]\n",
      " [  85   17   20    6   12   32 3145    1    7    0]\n",
      " [   4   90   20   29   44    0    0 3148    3  188]\n",
      " [  43   86   36  105   35  208   18   14 2620   49]\n",
      " [  22   22   19   49  123    9    0  193   13 2884]]\n",
      "\n",
      "Ratio: 0.8, K: 7\n",
      "Accuracy: 0.9082142857142858\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3275\n",
      "           1       0.89      0.99      0.94      3761\n",
      "           2       0.94      0.87      0.90      3357\n",
      "           3       0.87      0.92      0.89      3509\n",
      "           4       0.93      0.89      0.91      3265\n",
      "           5       0.89      0.87      0.88      3034\n",
      "           6       0.95      0.95      0.95      3325\n",
      "           7       0.92      0.88      0.90      3526\n",
      "           8       0.95      0.83      0.89      3214\n",
      "           9       0.85      0.89      0.87      3334\n",
      "\n",
      "    accuracy                           0.91     33600\n",
      "   macro avg       0.91      0.91      0.91     33600\n",
      "weighted avg       0.91      0.91      0.91     33600\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3201    3    6   11    7   16   22    1    8    0]\n",
      " [   0 3729    9    3    3    1    9    3    2    2]\n",
      " [  54   93 2915  130   23    4   42   51   35   10]\n",
      " [  19   38   50 3226    3   55    6   39   49   24]\n",
      " [   5   85   33   10 2914   17   10   19    2  170]\n",
      " [  34   38   13  151   17 2650   66   11   21   33]\n",
      " [  82   14   18    6   11   29 3158    1    6    0]\n",
      " [   6   89   20   22   37    2    0 3106    2  242]\n",
      " [  41   80   30   97   32  186   18   10 2665   55]\n",
      " [  22   25   15   48   99    7    0  152   14 2952]]\n",
      "\n",
      "Ratio: 0.8, K: 10\n",
      "Accuracy: 0.9033333333333333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.94      3275\n",
      "           1       0.87      0.99      0.93      3761\n",
      "           2       0.94      0.85      0.90      3357\n",
      "           3       0.87      0.91      0.89      3509\n",
      "           4       0.92      0.90      0.91      3265\n",
      "           5       0.89      0.87      0.88      3034\n",
      "           6       0.95      0.94      0.95      3325\n",
      "           7       0.91      0.89      0.90      3526\n",
      "           8       0.95      0.82      0.88      3214\n",
      "           9       0.85      0.87      0.86      3334\n",
      "\n",
      "    accuracy                           0.90     33600\n",
      "   macro avg       0.91      0.90      0.90     33600\n",
      "weighted avg       0.90      0.90      0.90     33600\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3195    3    6    9    7   17   27    1    8    2]\n",
      " [   0 3727    8    4    3    1    9    3    4    2]\n",
      " [  63  116 2864  128   29    6   47   54   40   10]\n",
      " [  20   44   50 3205    6   60    6   38   53   27]\n",
      " [   7   95   27   11 2925   19    9   13    3  156]\n",
      " [  37   51    9  149   18 2636   65   11   23   35]\n",
      " [  96   19   13    5   10   32 3142    1    7    0]\n",
      " [   5  100   14   22   46    1    0 3124    2  212]\n",
      " [  45  102   27   95   31  199   14   12 2632   57]\n",
      " [  20   28   14   48  121    7    0  182   12 2902]]\n",
      "\n",
      "Ratio: 0.9, K: 2\n",
      "Accuracy: 0.8693386243386243\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92      3688\n",
      "           1       0.87      0.99      0.92      4232\n",
      "           2       0.85      0.88      0.86      3780\n",
      "           3       0.82      0.88      0.85      3934\n",
      "           4       0.83      0.90      0.86      3670\n",
      "           5       0.83      0.83      0.83      3418\n",
      "           6       0.96      0.89      0.92      3695\n",
      "           7       0.86      0.89      0.87      3962\n",
      "           8       0.96      0.72      0.82      3641\n",
      "           9       0.90      0.72      0.80      3780\n",
      "\n",
      "    accuracy                           0.87     37800\n",
      "   macro avg       0.87      0.87      0.87     37800\n",
      "weighted avg       0.87      0.87      0.87     37800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3603    3   14    9    6   21   27    2    3    0]\n",
      " [   2 4192   17    2    8    1    3    4    1    2]\n",
      " [  94  172 3320   77   22    7   26   34   25    3]\n",
      " [  49   50  188 3469    7   84    5   29   42   11]\n",
      " [  26  106   63   17 3291   28    9   18    4  108]\n",
      " [  69   47   36  313   30 2842   44   13   12   12]\n",
      " [ 163   29   89    3   34   81 3293    1    2    0]\n",
      " [  10   98   53   67  106    2    1 3509    2  114]\n",
      " [  65  118  115  211   73  332   39   25 2626   37]\n",
      " [  33   31   30   82  380   23    0  462   23 2716]]\n",
      "\n",
      "Ratio: 0.9, K: 4\n",
      "Accuracy: 0.8910317460317461\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      3688\n",
      "           1       0.87      0.99      0.93      4232\n",
      "           2       0.90      0.86      0.88      3780\n",
      "           3       0.86      0.89      0.88      3934\n",
      "           4       0.89      0.90      0.89      3670\n",
      "           5       0.86      0.86      0.86      3418\n",
      "           6       0.95      0.93      0.94      3695\n",
      "           7       0.88      0.89      0.89      3962\n",
      "           8       0.94      0.79      0.86      3641\n",
      "           9       0.86      0.81      0.83      3780\n",
      "\n",
      "    accuracy                           0.89     37800\n",
      "   macro avg       0.89      0.89      0.89     37800\n",
      "weighted avg       0.89      0.89      0.89     37800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3592    2   11    8    6   19   36    1   11    2]\n",
      " [   1 4180   13    8    9    0   10    4    4    3]\n",
      " [  85  136 3264  108   21    5   41   67   43   10]\n",
      " [  33   53  107 3511    5   93    7   39   60   26]\n",
      " [  18  102   44   12 3290   28   15   17    4  140]\n",
      " [  57   62   17  199   24 2931   52   11   34   31]\n",
      " [ 122   19   31    3   13   48 3451    3    5    0]\n",
      " [   9   98   25   33   67    0    0 3512    0  218]\n",
      " [  47  116   72  127   41  259   17    9 2888   65]\n",
      " [  26   27   26   61  235   15    0  309   19 3062]]\n",
      "\n",
      "Ratio: 0.9, K: 5\n",
      "Accuracy: 0.8932539682539683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3688\n",
      "           1       0.87      0.99      0.92      4232\n",
      "           2       0.93      0.85      0.89      3780\n",
      "           3       0.87      0.90      0.89      3934\n",
      "           4       0.89      0.88      0.89      3670\n",
      "           5       0.86      0.86      0.86      3418\n",
      "           6       0.95      0.94      0.94      3695\n",
      "           7       0.90      0.87      0.89      3962\n",
      "           8       0.94      0.80      0.86      3641\n",
      "           9       0.83      0.85      0.84      3780\n",
      "\n",
      "    accuracy                           0.89     37800\n",
      "   macro avg       0.90      0.89      0.89     37800\n",
      "weighted avg       0.89      0.89      0.89     37800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3586    3   13    8    6   23   38    1    8    2]\n",
      " [   0 4183   14    7    8    1    9    4    3    3]\n",
      " [  73  144 3218  131   28    5   47   80   46    8]\n",
      " [  26   52   67 3543    7   96    8   34   78   23]\n",
      " [  16   98   37    8 3241   31   11   16    1  211]\n",
      " [  55   70   11  172   24 2939   66   11   34   36]\n",
      " [  99   25   24    4   13   43 3482    3    2    0]\n",
      " [   8   98   18   30   69    0    1 3449    2  287]\n",
      " [  55  119   58  113   38  242   19   10 2920   67]\n",
      " [  23   29   17   55  203   21    0  207   21 3204]]\n",
      "\n",
      "Ratio: 0.9, K: 6\n",
      "Accuracy: 0.891084656084656\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3688\n",
      "           1       0.85      0.99      0.92      4232\n",
      "           2       0.93      0.85      0.89      3780\n",
      "           3       0.87      0.90      0.88      3934\n",
      "           4       0.88      0.89      0.89      3670\n",
      "           5       0.87      0.85      0.86      3418\n",
      "           6       0.95      0.94      0.94      3695\n",
      "           7       0.89      0.88      0.89      3962\n",
      "           8       0.94      0.79      0.86      3641\n",
      "           9       0.85      0.83      0.84      3780\n",
      "\n",
      "    accuracy                           0.89     37800\n",
      "   macro avg       0.89      0.89      0.89     37800\n",
      "weighted avg       0.89      0.89      0.89     37800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3596    3   10   10    6   21   32    1    7    2]\n",
      " [   0 4187   11    9    5    1    9    3    4    3]\n",
      " [  93  166 3200  115   30    5   40   72   51    8]\n",
      " [  26   58   66 3549   10   84    8   38   73   22]\n",
      " [  16  111   38   10 3272   29   10   17    1  166]\n",
      " [  60   83   15  189   29 2907   60   11   29   35]\n",
      " [ 116   28   27    3   13   43 3458    2    5    0]\n",
      " [   8  109   15   28   72    0    0 3501    2  227]\n",
      " [  54  128   48  121   46  253   18   12 2892   69]\n",
      " [  23   37   17   56  229   16    0  262   19 3121]]\n",
      "\n",
      "Ratio: 0.9, K: 7\n",
      "Accuracy: 0.8911111111111111\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3688\n",
      "           1       0.85      0.99      0.91      4232\n",
      "           2       0.94      0.84      0.88      3780\n",
      "           3       0.87      0.90      0.89      3934\n",
      "           4       0.89      0.88      0.89      3670\n",
      "           5       0.87      0.85      0.86      3418\n",
      "           6       0.95      0.94      0.94      3695\n",
      "           7       0.91      0.87      0.89      3962\n",
      "           8       0.93      0.80      0.86      3641\n",
      "           9       0.83      0.85      0.84      3780\n",
      "\n",
      "    accuracy                           0.89     37800\n",
      "   macro avg       0.89      0.89      0.89     37800\n",
      "weighted avg       0.89      0.89      0.89     37800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3590    4    9    8    5   21   38    1   10    2]\n",
      " [   0 4189   10    8    4    2    9    2    5    3]\n",
      " [  75  174 3160  130   38    5   46   81   61   10]\n",
      " [  23   60   57 3547   12   79    8   38   85   25]\n",
      " [  16  108   28   10 3234   30    9   13    0  222]\n",
      " [  56   94   14  183   26 2892   71   13   33   36]\n",
      " [ 105   30   23    4   11   39 3475    3    5    0]\n",
      " [   6  113   14   23   71    0    0 3448    2  285]\n",
      " [  52  131   43  115   40  238   18   12 2918   74]\n",
      " [  23   37   17   51  196   21    0  186   18 3231]]\n",
      "\n",
      "Ratio: 0.9, K: 10\n",
      "Accuracy: 0.8863227513227513\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      3688\n",
      "           1       0.82      0.99      0.90      4232\n",
      "           2       0.94      0.81      0.87      3780\n",
      "           3       0.87      0.90      0.88      3934\n",
      "           4       0.89      0.89      0.89      3670\n",
      "           5       0.87      0.84      0.85      3418\n",
      "           6       0.94      0.93      0.94      3695\n",
      "           7       0.90      0.87      0.88      3962\n",
      "           8       0.93      0.80      0.86      3641\n",
      "           9       0.83      0.84      0.84      3780\n",
      "\n",
      "    accuracy                           0.89     37800\n",
      "   macro avg       0.89      0.88      0.89     37800\n",
      "weighted avg       0.89      0.89      0.89     37800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3589    5    5   10    8   23   36    1    8    3]\n",
      " [   0 4194   10    8    2    1    8    2    4    3]\n",
      " [  88  217 3076  142   43    3   53   84   63   11]\n",
      " [  24   83   46 3521   10   80   13   46   82   29]\n",
      " [  15  125   22   13 3254   29    9   15    1  187]\n",
      " [  51  111    9  187   30 2862   72   14   35   47]\n",
      " [ 118   38   21    4   17   34 3453    3    7    0]\n",
      " [   7  135   13   15   64    0    0 3452    2  274]\n",
      " [  56  135   36  113   40  239   15   16 2915   76]\n",
      " [  26   47   18   52  205   10    0  221   14 3187]]\n",
      "\n",
      "Ratio: 0.95, K: 2\n",
      "Accuracy: 0.8464411027568922\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      3909\n",
      "           1       0.83      0.99      0.90      4450\n",
      "           2       0.83      0.85      0.84      3967\n",
      "           3       0.79      0.86      0.83      4146\n",
      "           4       0.81      0.86      0.83      3883\n",
      "           5       0.80      0.80      0.80      3606\n",
      "           6       0.95      0.86      0.91      3908\n",
      "           7       0.84      0.86      0.85      4188\n",
      "           8       0.96      0.67      0.79      3863\n",
      "           9       0.87      0.70      0.78      3980\n",
      "\n",
      "    accuracy                           0.85     39900\n",
      "   macro avg       0.85      0.84      0.84     39900\n",
      "weighted avg       0.85      0.85      0.84     39900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3818    2   15    8   16   19   21    0    9    1]\n",
      " [   2 4404   21    5    5    1    3    6    2    1]\n",
      " [ 186  171 3375   90   35    5   26   45   31    3]\n",
      " [  70   78  218 3579   10  101   10   32   29   19]\n",
      " [  37  167   64   16 3352   41   10   32    3  161]\n",
      " [ 101   76   39  353   68 2868   57   14   13   17]\n",
      " [ 200   60  129    2   43   93 3377    1    3    0]\n",
      " [  12  149   46   92  114    6    1 3609    2  157]\n",
      " [  74  164  140  277  105  400   45   22 2593   43]\n",
      " [  34   47   17   84  414   45    0  517   24 2798]]\n",
      "\n",
      "Ratio: 0.95, K: 4\n",
      "Accuracy: 0.8689724310776943\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      3909\n",
      "           1       0.82      0.99      0.89      4450\n",
      "           2       0.91      0.83      0.87      3967\n",
      "           3       0.86      0.88      0.87      4146\n",
      "           4       0.86      0.85      0.86      3883\n",
      "           5       0.84      0.82      0.83      3606\n",
      "           6       0.95      0.92      0.93      3908\n",
      "           7       0.87      0.87      0.87      4188\n",
      "           8       0.93      0.75      0.83      3863\n",
      "           9       0.82      0.80      0.81      3980\n",
      "\n",
      "    accuracy                           0.87     39900\n",
      "   macro avg       0.87      0.87      0.87     39900\n",
      "weighted avg       0.87      0.87      0.87     39900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3801    3   11    9    9   30   30    1   11    4]\n",
      " [   0 4406   15    8    4    0    7    5    3    2]\n",
      " [ 146  201 3286  116   43    5   35   63   58   14]\n",
      " [  47   91   92 3646    9  118   10   37   65   31]\n",
      " [  25  167   33   12 3307   44   17   20    2  256]\n",
      " [  91  104   18  222   50 2946   77   14   42   42]\n",
      " [ 141   57   45    2   22   43 3587    2    9    0]\n",
      " [   8  166   18   21   68    1    0 3623    1  282]\n",
      " [  71  157   78  161   69  317   29   22 2885   74]\n",
      " [  26   50   20   43  249   24    0  363   20 3185]]\n",
      "\n",
      "Ratio: 0.95, K: 5\n",
      "Accuracy: 0.8670426065162907\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      3909\n",
      "           1       0.81      0.99      0.89      4450\n",
      "           2       0.93      0.81      0.86      3967\n",
      "           3       0.86      0.87      0.87      4146\n",
      "           4       0.87      0.83      0.85      3883\n",
      "           5       0.83      0.82      0.82      3606\n",
      "           6       0.94      0.93      0.94      3908\n",
      "           7       0.89      0.84      0.86      4188\n",
      "           8       0.93      0.76      0.83      3863\n",
      "           9       0.78      0.83      0.81      3980\n",
      "\n",
      "    accuracy                           0.87     39900\n",
      "   macro avg       0.87      0.87      0.87     39900\n",
      "weighted avg       0.87      0.87      0.87     39900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3795    7   12    7    8   29   37    1   10    3]\n",
      " [   0 4408   15    5    5    0    8    4    3    2]\n",
      " [ 135  219 3212  151   54    5   47   72   59   13]\n",
      " [  38   97   79 3624   10  139   12   43   72   32]\n",
      " [  25  172   26   11 3211   45   10   22    1  360]\n",
      " [  85  118   10  203   41 2942   87   15   59   46]\n",
      " [ 106   48   29    3   23   44 3648    1    6    0]\n",
      " [   8  170   14   28   64    0    0 3517    2  385]\n",
      " [  59  158   57  149   73  311   30   19 2928   79]\n",
      " [  29   56   16   48  211   21    0  266   23 3310]]\n",
      "\n",
      "Ratio: 0.95, K: 6\n",
      "Accuracy: 0.8655388471177945\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      3909\n",
      "           1       0.79      0.99      0.88      4450\n",
      "           2       0.92      0.80      0.86      3967\n",
      "           3       0.86      0.88      0.87      4146\n",
      "           4       0.87      0.84      0.86      3883\n",
      "           5       0.84      0.81      0.82      3606\n",
      "           6       0.94      0.92      0.93      3908\n",
      "           7       0.88      0.85      0.86      4188\n",
      "           8       0.93      0.75      0.83      3863\n",
      "           9       0.80      0.81      0.81      3980\n",
      "\n",
      "    accuracy                           0.87     39900\n",
      "   macro avg       0.87      0.86      0.86     39900\n",
      "weighted avg       0.87      0.87      0.86     39900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3806    8   10    5    7   27   30    1   12    3]\n",
      " [   0 4413   14    4    3    0    9    2    3    2]\n",
      " [ 146  252 3186  133   55    5   41   76   59   14]\n",
      " [  43  106   82 3633   14  112   13   39   69   35]\n",
      " [  27  183   24   11 3281   39   15   14    3  286]\n",
      " [  85  148   12  220   42 2917   79   15   38   50]\n",
      " [ 122   66   36    3   27   51 3600    0    3    0]\n",
      " [   9  188   12   24   63    0    0 3551    2  339]\n",
      " [  67  180   57  144   67  303   26   18 2910   91]\n",
      " [  32   68   15   52  223   17    0  316   19 3238]]\n",
      "\n",
      "Ratio: 0.95, K: 7\n",
      "Accuracy: 0.8648370927318296\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93      3909\n",
      "           1       0.78      0.99      0.87      4450\n",
      "           2       0.93      0.79      0.86      3967\n",
      "           3       0.86      0.87      0.87      4146\n",
      "           4       0.88      0.83      0.85      3883\n",
      "           5       0.84      0.81      0.82      3606\n",
      "           6       0.94      0.93      0.93      3908\n",
      "           7       0.89      0.83      0.86      4188\n",
      "           8       0.93      0.76      0.84      3863\n",
      "           9       0.78      0.84      0.81      3980\n",
      "\n",
      "    accuracy                           0.86     39900\n",
      "   macro avg       0.87      0.86      0.86     39900\n",
      "weighted avg       0.87      0.86      0.86     39900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3798    9   12    5    9   30   31    1   12    2]\n",
      " [   0 4416   14    5    4    0    7    1    2    1]\n",
      " [ 141  267 3144  145   60    6   49   83   61   11]\n",
      " [  37  112   73 3621   11  113   15   43   81   40]\n",
      " [  26  185   17   10 3231   39   13   14    2  346]\n",
      " [  78  151   14  198   38 2915   85   15   55   57]\n",
      " [ 111   66   30    3   28   41 3624    0    5    0]\n",
      " [  10  207   12   20   56    2    0 3470    1  410]\n",
      " [  60  177   52  135   66  297   20   15 2947   94]\n",
      " [  33   68   15   51  187   22    0  246   17 3341]]\n",
      "\n",
      "Ratio: 0.95, K: 10\n",
      "Accuracy: 0.8595488721804512\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      3909\n",
      "           1       0.74      0.99      0.85      4450\n",
      "           2       0.94      0.78      0.85      3967\n",
      "           3       0.87      0.87      0.87      4146\n",
      "           4       0.88      0.83      0.85      3883\n",
      "           5       0.84      0.79      0.82      3606\n",
      "           6       0.95      0.91      0.93      3908\n",
      "           7       0.90      0.83      0.86      4188\n",
      "           8       0.93      0.76      0.83      3863\n",
      "           9       0.78      0.84      0.81      3980\n",
      "\n",
      "    accuracy                           0.86     39900\n",
      "   macro avg       0.87      0.86      0.86     39900\n",
      "weighted avg       0.87      0.86      0.86     39900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3816   10    5    3    7   33   24    1    8    2]\n",
      " [   0 4420    9    4    5    0    6    2    2    2]\n",
      " [ 156  329 3079  136   68    4   44   67   69   15]\n",
      " [  39  142   66 3600    8  108   16   40   81   46]\n",
      " [  24  205   10    9 3231   38   10   16    1  339]\n",
      " [  80  205    9  196   44 2863   79   14   47   69]\n",
      " [ 134   91   36    3   30   43 3567    1    3    0]\n",
      " [  14  238   13   16   54    1    0 3460    1  391]\n",
      " [  64  213   35  132   62  297   20   14 2928   98]\n",
      " [  35   86   11   52  183   20    0  245   16 3332]]\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.60, 0.70, 0.75, 0.80, 0.90, 0.95]\n",
    "k_values = [2, 4, 5, 6, 7, 10]\n",
    "results=[]\n",
    "for ratioo in ratios:\n",
    "    for k in k_values:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=ratioo, random_state=40)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "        x_train_scaled = scaler.transform(x_train)\n",
    "        x_test_scaled = scaler.transform(x_test)\n",
    "        \n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        classifier.fit(x_train_scaled, y_train)\n",
    "        \n",
    "        y_pred = classifier.predict(x_test_scaled)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nRatio: {ratioo}, K: {k}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "        results.append({\n",
    "            'Ratio': ratioo,\n",
    "            'K': k,\n",
    "            'Accuracy': accuracy,\n",
    "            'Classification Report': cr,\n",
    "            'Confusion Matrix': cm\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cffad070-2919-479f-86f3-1faca7359b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "086525cb-5cfb-44ae-b328-7cbedf1723e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a87adaa-d735-429a-bd86-a62ecc0ba63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ratio   K  Accuracy                              Classification Report  \\\n",
      "0    0.60   2  0.907302  {'0': {'precision': 0.91350531107739, 'recall'...   \n",
      "1    0.60   4  0.921508  {'0': {'precision': 0.9338006230529595, 'recal...   \n",
      "2    0.60   5  0.924444  {'0': {'precision': 0.9436342136381553, 'recal...   \n",
      "3    0.60   6  0.923095  {'0': {'precision': 0.9406912804399057, 'recal...   \n",
      "4    0.60   7  0.923571  {'0': {'precision': 0.944729569680221, 'recall...   \n",
      "5    0.60  10  0.919563  {'0': {'precision': 0.939417781274587, 'recall...   \n",
      "6    0.70   2  0.902041  {'0': {'precision': 0.9056056701030928, 'recal...   \n",
      "7    0.70   4  0.915544  {'0': {'precision': 0.9276989105315285, 'recal...   \n",
      "8    0.70   5  0.919184  {'0': {'precision': 0.9347101932045303, 'recal...   \n",
      "9    0.70   6  0.917551  {'0': {'precision': 0.9301324503311258, 'recal...   \n",
      "10   0.70   7  0.917823  {'0': {'precision': 0.9355162044771133, 'recal...   \n",
      "11   0.70  10  0.911735  {'0': {'precision': 0.9295212765957447, 'recal...   \n",
      "12   0.75   2  0.898095  {'0': {'precision': 0.8981481481481481, 'recal...   \n",
      "13   0.75   4  0.913429  {'0': {'precision': 0.9240233774223315, 'recal...   \n",
      "14   0.75   5  0.916603  {'0': {'precision': 0.9353730877302529, 'recal...   \n",
      "15   0.75   6  0.913841  {'0': {'precision': 0.9283276450511946, 'recal...   \n",
      "16   0.75   7  0.913714  {'0': {'precision': 0.9294592914853946, 'recal...   \n",
      "17   0.75  10  0.910032  {'0': {'precision': 0.9257884972170687, 'recal...   \n",
      "18   0.80   2  0.891637  {'0': {'precision': 0.8894416804864566, 'recal...   \n",
      "19   0.80   4  0.908095  {'0': {'precision': 0.9141471762692527, 'recal...   \n",
      "20   0.80   5  0.909643  {'0': {'precision': 0.9252740911713792, 'recal...   \n",
      "21   0.80   6  0.907381  {'0': {'precision': 0.9196095320126327, 'recal...   \n",
      "22   0.80   7  0.908214  {'0': {'precision': 0.9240762124711316, 'recal...   \n",
      "23   0.80  10  0.903333  {'0': {'precision': 0.9159977064220184, 'recal...   \n",
      "24   0.90   2  0.869339  {'0': {'precision': 0.8757899854156539, 'recal...   \n",
      "25   0.90   4  0.891032  {'0': {'precision': 0.9002506265664161, 'recal...   \n",
      "26   0.90   5  0.893254  {'0': {'precision': 0.9099213397614818, 'recal...   \n",
      "27   0.90   6  0.891085  {'0': {'precision': 0.9008016032064128, 'recal...   \n",
      "28   0.90   7  0.891111  {'0': {'precision': 0.9097820577800304, 'recal...   \n",
      "29   0.90  10  0.886323  {'0': {'precision': 0.9031202818319074, 'recal...   \n",
      "30   0.95   2  0.846441  {'0': {'precision': 0.8420820467578297, 'recal...   \n",
      "31   0.95   4  0.868972  {'0': {'precision': 0.8725895316804407, 'recal...   \n",
      "32   0.95   5  0.867043  {'0': {'precision': 0.8866822429906542, 'recal...   \n",
      "33   0.95   6  0.865539  {'0': {'precision': 0.8775651371916071, 'recal...   \n",
      "34   0.95   7  0.864837  {'0': {'precision': 0.8844899860270145, 'recal...   \n",
      "35   0.95  10  0.859549  {'0': {'precision': 0.874828060522696, 'recall...   \n",
      "\n",
      "                                     Confusion Matrix  \n",
      "0   [[2408, 2, 7, 4, 2, 7, 10, 1, 2, 0], [2, 2782,...  \n",
      "1   [[2398, 1, 7, 5, 1, 8, 17, 1, 4, 1], [2, 2783,...  \n",
      "2   [[2394, 1, 4, 6, 2, 8, 22, 2, 4, 0], [1, 2781,...  \n",
      "3   [[2395, 0, 4, 6, 1, 9, 19, 3, 6, 0], [0, 2782,...  \n",
      "4   [[2393, 1, 4, 6, 1, 10, 20, 3, 5, 0], [0, 2782...  \n",
      "5   [[2388, 2, 5, 5, 2, 10, 23, 3, 5, 0], [0, 2785...  \n",
      "6   [[2811, 5, 9, 6, 3, 7, 15, 0, 4, 0], [2, 3235,...  \n",
      "7   [[2810, 3, 6, 6, 2, 11, 15, 2, 5, 0], [2, 3231...  \n",
      "8   [[2806, 3, 6, 5, 3, 10, 19, 2, 5, 1], [3, 3225...  \n",
      "9   [[2809, 2, 3, 5, 5, 9, 18, 3, 5, 1], [1, 3231,...  \n",
      "10  [[2800, 3, 3, 6, 6, 9, 23, 2, 7, 1], [0, 3232,...  \n",
      "11  [[2796, 3, 6, 5, 6, 12, 22, 2, 7, 1], [0, 3234...  \n",
      "12  [[3007, 3, 11, 6, 3, 5, 17, 2, 3, 0], [5, 3490...  \n",
      "13  [[3004, 3, 8, 8, 2, 11, 15, 2, 4, 0], [3, 3489...  \n",
      "14  [[2996, 4, 5, 11, 5, 11, 18, 2, 3, 2], [1, 348...  \n",
      "15  [[2992, 3, 6, 8, 8, 10, 22, 2, 5, 1], [0, 3491...  \n",
      "16  [[2991, 3, 5, 8, 8, 11, 22, 2, 6, 1], [0, 3489...  \n",
      "17  [[2994, 3, 7, 6, 7, 12, 22, 1, 4, 1], [0, 3493...  \n",
      "18  [[3218, 3, 13, 6, 4, 9, 17, 2, 3, 0], [6, 3726...  \n",
      "19  [[3205, 3, 10, 8, 3, 16, 20, 2, 8, 0], [2, 372...  \n",
      "20  [[3207, 4, 8, 9, 6, 15, 19, 2, 5, 0], [0, 3723...  \n",
      "21  [[3203, 3, 9, 11, 6, 16, 20, 1, 6, 0], [0, 373...  \n",
      "22  [[3201, 3, 6, 11, 7, 16, 22, 1, 8, 0], [0, 372...  \n",
      "23  [[3195, 3, 6, 9, 7, 17, 27, 1, 8, 2], [0, 3727...  \n",
      "24  [[3603, 3, 14, 9, 6, 21, 27, 2, 3, 0], [2, 419...  \n",
      "25  [[3592, 2, 11, 8, 6, 19, 36, 1, 11, 2], [1, 41...  \n",
      "26  [[3586, 3, 13, 8, 6, 23, 38, 1, 8, 2], [0, 418...  \n",
      "27  [[3596, 3, 10, 10, 6, 21, 32, 1, 7, 2], [0, 41...  \n",
      "28  [[3590, 4, 9, 8, 5, 21, 38, 1, 10, 2], [0, 418...  \n",
      "29  [[3589, 5, 5, 10, 8, 23, 36, 1, 8, 3], [0, 419...  \n",
      "30  [[3818, 2, 15, 8, 16, 19, 21, 0, 9, 1], [2, 44...  \n",
      "31  [[3801, 3, 11, 9, 9, 30, 30, 1, 11, 4], [0, 44...  \n",
      "32  [[3795, 7, 12, 7, 8, 29, 37, 1, 10, 3], [0, 44...  \n",
      "33  [[3806, 8, 10, 5, 7, 27, 30, 1, 12, 3], [0, 44...  \n",
      "34  [[3798, 9, 12, 5, 9, 30, 31, 1, 12, 2], [0, 44...  \n",
      "35  [[3816, 10, 5, 3, 7, 33, 24, 1, 8, 2], [0, 442...  \n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98b2f8-d141-4234-b48d-e8fa732a8715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
